import os

import pandas as pd
import streamlit as st
from langsmith import Client

os.environ["LANGCHAIN_TRACING_V2"] = st.secrets.langsmith.tracing
os.environ["LANGCHAIN_ENDPOINT"] = st.secrets.langsmith.endpoint
os.environ["LANGCHAIN_API_KEY"] = st.secrets.langsmith.api_key
os.environ["LANGCHAIN_PROJECT"] = st.secrets.langsmith.project


if __name__ == "__main__":
    st.set_page_config(
        page_title="Langsmith Data",
        page_icon="ðŸ¦œ",
        layout="wide",
        initial_sidebar_state="collapsed",
    )
    st.title("ðŸ“Š UNAP Chatbot Langsmith Runs Data")
    st.markdown("Tracings registrados en la organizacion **unap-chabot** en Langsmith.")
    client = Client()

    fcol1, fcol2, fcol3 = st.columns(3)
    with fcol1:
        env_type = st.selectbox("Entorno de chat", ["--", "Test Chat", "WebApp Chat"])

    if env_type != "--":
        project_list = client.list_runs(
            project_name=st.secrets.langsmith.project,
            execution_order=1,
            filter=f"has(tags, '{env_type}')",
        )
    else:
        project_list = client.list_runs(
            project_name=st.secrets.langsmith.project, execution_order=1
        )

    # Define the attributes of interest
    project_list = [
        {
            "name": str(run.name),
            "run_type": str(run.run_type),
            "tags": run.tags,
            "inputs": run.inputs,
            "outputs": run.outputs,
            "error": run.error,
            "extra": run.extra,
            "start_time": run.start_time,
            "end_time": run.end_time,
            "status": run.status,
            "feedback_stats": run.feedback_stats,
            "prompt_tokens": run.prompt_tokens,
            "completion_tokens": run.completion_tokens,
            "total_tokens": run.total_tokens,
        }
        for run in project_list
    ]

    # Convert project_list to a DataFrame
    project_list_df = pd.DataFrame(project_list)

    # Normalize the 'outputs' column and join it to the original DataFrame
    outputs_df = pd.json_normalize(project_list_df["outputs"].tolist(), sep="_")
    project_list_df = project_list_df.drop(columns="outputs").join(outputs_df)
    # Normalize the 'extra' column and join it to the original DataFrame
    extra_df = pd.json_normalize(project_list_df["extra"].tolist(), sep="_")
    project_list_df = project_list_df.drop(columns="extra").join(extra_df)

    # Create a new column 'total' with the calculated values of 'prompt_tokens' and 'completion_tokens'
    project_list_df["total"] = ((project_list_df["prompt_tokens"] / 1000) * 0.0010) + (
        (project_list_df["completion_tokens"] / 1000) * 0.0020
    )

    # Filter the DataFrame according to the selected status
    with fcol2:
        filter_by_status = st.selectbox("Estado", ["--", "success", "error"])
    if filter_by_status != "--":
        project_list_df = project_list_df[project_list_df["status"] == filter_by_status]

    sessions = project_list_df["metadata_user_session"].unique()
    with fcol3:
        filter_by_session = st.multiselect(
            "Sesion", list(sessions), placeholder="Elija una o mas sesiones"
        )

    if filter_by_session:
        project_list_df = project_list_df[
            project_list_df["metadata_user_session"].isin(filter_by_session)
        ]

    # Display the DataFrame
    st.dataframe(
        project_list_df,
        use_container_width=True,
        column_order=[
            "name",
            "run_type",
            "question",
            "answer",
            "status",
            "error",
            "feedback_stats",
            "start_time",
            "end_time",
            "prompt_tokens",
            "completion_tokens",
            "total_tokens",
            "total",
            "tags",
            "metadata_user_session",
            "chat_history",
            "context",
        ],
        column_config={
            "name": st.column_config.Column("Nombre", width="small"),
            "run_type": st.column_config.Column("Tipo", width="small"),
            "question": st.column_config.Column("Pregunta", width="medium"),
            "answer": st.column_config.Column("Respuesta", width="medium"),
            "status": st.column_config.Column("Estado", width="small"),
            "error": st.column_config.Column("Error", width="snmall"),
            "feedback_stats": "Feedback",
            "start_time": st.column_config.DatetimeColumn(
                "Inicio", format="D MMM YYYY, HH:mm:ss", width="small"
            ),
            "end_time": st.column_config.DatetimeColumn(
                "Fin", format="D MMM YYYY, HH:mm:ss", width="small"
            ),
            "prompt_tokens": "Tokens de pregunta",
            "completion_tokens": "Tokens de respuesta",
            "total_tokens": "Tokens totales",
            "total": st.column_config.NumberColumn(
                "Costo (USD)", format="%.4f", width="small"
            ),
            "tags": st.column_config.Column("Tags", width="small"),
            "metadata_user_session": st.column_config.Column("Sesion", width="small"),
            "chat_history": st.column_config.Column("Historial", width="small"),
            "context": st.column_config.Column("Contexto", width="small"),
        },
    )

    # Calculate the total values
    total_runs = len(project_list_df)
    total_tokens_sum = project_list_df["total_tokens"].sum()
    total_sum = project_list_df["total"].sum()

    total_tokens_avg = project_list_df["total_tokens"].mean()

    # Display the total values
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total de ejecuciones:", total_runs)
    with col2:
        st.metric("Tokens Promedio:", f"{total_tokens_avg:.2f}")
    with col3:
        st.metric("Tokens Totales:", total_tokens_sum)
    with col4:
        st.metric("Costo Total (USD):", f"{total_sum:.4f}")
